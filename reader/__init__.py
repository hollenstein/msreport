""" Module for reading and homogenizing result tables from various MS analysis
tools. Currently MaxQuant and FragPipe protein tables are fully supported, and
ion and peptide tables are partly supported.

New or changed column names:
- Spectral count "sample name"
- Unique spectral count "sample name"
- Total spectral count "sample name"
- LFQ intensity "sample name"
- Intensity "sample name"
- Total peptides
- Representative protein
- Leading proteins

Todos:
- Add full support for ion (evidence) and peptide tables

FP reader:
- For LFQ the most relevant files are combined_protein.tsv, combined_ion.tsv
- For TMT the relevant files are protein.tsv, psm.tsv (might be in folders)
"""


from collections import OrderedDict
import pandas as pd
import os
import helper
import maspy._proteindb_refactoring as ProtDB


class ResultReader():
    """ Base Reader class, is by itself not functional. """
    filenames_default: dict[str, str]
    sample_column_tags: list[str]
    column_mapping: dict[str, str]
    column_tag_mapping: OrderedDict[str, str]

    def _read_file(self, which: str) -> pd.DataFrame:
        """ Read a result table from the data_directory

        Args:
            which: Used to lookup the file name in self.filenames
        """
        filepath = os.path.join(self.data_directory, self.filenames[which])
        df = pd.read_csv(filepath, sep='\t')
        str_cols = df.select_dtypes(include=['object']).columns
        df.loc[:, str_cols] = df.loc[:, str_cols].fillna('')
        return df

    def _rename_columns(self, df: pd.DataFrame,
                        prefix_tag: bool) -> pd.DataFrame:
        """ Returns a new DataFrame with renamed columns.

        First columns are renamed according to self.column_mapping. Next, tags
        in columns are renamed according to self.column_tag_mapping. Then, for
        columns containing sample names, sample names are and tags are
        rearranged.
        """
        new_df = df.copy()
        new_df.rename(columns=self.column_mapping, inplace=True)
        for old_tag, new_tag in self.column_tag_mapping.items():
            new_df = _replace_column_tag(new_df, old_tag, new_tag)

        for tag in self.sample_column_tags:
            if tag in self.column_tag_mapping:
                tag = self.column_tag_mapping[tag]
            new_df = _rearrange_column_tag(new_df, tag, prefix_tag)
        return new_df

    def _drop_columns(self, df: pd.DataFrame,
                      columns_to_drop: list[str]) -> pd.DataFrame:
        """ Returns a new data frame without the specified columns. """
        remaining_columns = []
        for column in df.columns:
            if column not in columns_to_drop:
                remaining_columns.append(column)
        new_df = df[remaining_columns].copy()
        return new_df


class MQReader(ResultReader):
    """ Import and preprocess MaxQuant result files.

    Attributes:
        filenames_default: (class attribute) Look up of filenames for the
            result files generated by MaxQuant.
        sample_column_tags: (class attribute) Column tags for which an
            additional column is present per sample.
        column_mapping: (class attribute) Used to rename original column names
            from MaxQuant with the internal standardized names.
        column_tag_mapping: (class attribute) Mapping of 'Old substring' to
            'New substring' that will be replaced in column names. Used to
            rename intensity and spectral count columns.
        protein_info_columns: (class attribute) List of columns that contain
            protein specific information.

        data_directory (str): Location of the MaxQuant 'txt' folder
        contamination_tag (str): Substring present in protein IDs to identify
            them as potential contaminants.
    """
    filenames_default: dict[str, str] = {
        'proteins': 'proteinGroups.txt',
        'peptides': 'peptides.txt',
        'ions': 'evidence.txt'
    }
    sample_column_tags: list[str] = [
        'LFQ intensity', 'Intensity', 'iBAQ',
        'MS/MS count', 'Sequence coverage',
    ]
    column_mapping: dict[str, str] = dict([
        ('Peptides', 'Total peptides'),
    ])
    column_tag_mapping: OrderedDict[str, str] = OrderedDict([
        ('MS/MS count', 'Spectral count'),
    ])
    protein_info_columns: list[str] = [
        'Protein names', 'Gene names', 'Fasta headers'
        'Sequence coverage [%]', 'Unique + razor sequence coverage [%]',
        'Unique sequence coverage [%]', 'Mol. weight [kDa]', 'Sequence length',
        'Sequence lengths', 'iBAQ peptides'
    ]

    def __init__(self, directory: str, isobar: bool = False,
                 contaminant_tag: str = 'CON_') -> None:
        """
        Args:
            directory: Location of the MaxQuant 'txt' folder
            isobar: True if quantification strategy was TMT, iTRAQ or similar
            contaminant_tag: Prefix of Protein ID entries to identify
                contaminations

        Attributes:
            data_directory: Location of the MaxQuant 'txt' folder
            filenames: Look up of filenames generated by MaxQuant
        """
        self.data_directory: str = directory
        self.filenames: dict[str, str] = self.filenames_default
        self._isobar: bool = isobar
        self._contaminant_tag: str = contaminant_tag

    def import_proteins(self,
                        rename_columns: bool = True,
                        drop_decoy: bool = True,
                        drop_idbysite: bool = True,
                        prefix_column_tags: bool = True,
                        rearrange_proteins: bool = True,
                        drop_protein_info: bool = True,
                        special_proteins: list[str] = []) -> pd.DataFrame:
        """ Read and process 'proteinGroups.txt' file """
        df = self._read_file('proteins')
        if drop_decoy:
            df = self._drop_decoy(df)
        if drop_idbysite:
            df = self._drop_idbysite(df)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        if rearrange_proteins:
            df = self._rearrange_proteins(df, special_proteins)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
        return df

    def import_peptides(self, drop_decoy: bool = True,
                        prefix_column_tags: bool = True) -> pd.DataFrame:
        """ Read and process 'peptides.txt' file """
        df = self._read_file('peptides')
        if drop_decoy:
            df = self._drop_decoy(df)
        df = self._rename_columns(df, prefix_column_tags)
        return df

    # def import_ions(self, drop_decoy: bool = True) -> pd.DataFrame:
    #     """ Read and process 'evidence.txt' file """
    #     df = self._read_file('ions')
    #     if drop_decoy:
    #         df = self._drop_decoy(df)
    #     return df

    def _drop_decoy(self, df: pd.DataFrame) -> pd.DataFrame:
        """ Removes rows with '+' in the 'Reverse' column """
        return df.loc[df['Reverse'] != '+']

    def _drop_idbysite(self, df: pd.DataFrame) -> pd.DataFrame:
        """ Removes rows with '+' in the 'Only identified by site' column """
        return df.loc[df['Only identified by site'] != '+']

    def _rearrange_proteins(self, df: pd.DataFrame,
                            special_proteins: list[str] = []
                            ) -> pd.DataFrame:
        """ Sorts proteins and adds three newcolumns to the dataframe.

        "Leading proteins" contains all protein entries from the
        "Majority protein IDs" column, which have the same and highest number
        of peptide in the "Peptide counts (all)" column.
        Multiple protein entries are separated by ";". Special proteins are
        listed first and proteins containing the contamination tag are listed
        last. The other proteins are sorted alphabetically ascending.

        "Representative protein" contains only the first entry from the new
        "Leading proteins" column.

        "Protein reported by software" contains the original
        first entry from the "Majority protein IDs" column.
        """
        sorting_tag_levels = {self._contaminant_tag: 1}
        sorting_tag_levels.update({p: -1 for p in special_proteins})

        reported_entries = []
        leading_entries = []
        representative_entries = []
        for majority_ids_entry, count_entry in zip(df['Majority protein IDs'],
                                                   df['Peptide counts (all)']):
            proteins = majority_ids_entry.split(';')
            counts = [int(i) for i in count_entry.split(';')]
            highest_count = max(counts)
            leading_proteins = [f for f, c in zip(proteins, counts)
                                if c >= highest_count]

            fastas, sorted_proteins, names = _sort_fasta_entries(
                leading_proteins, sorting_tag_levels
            )
            reported_entries.append(leading_proteins[0])
            leading_entries.append(';'.join(sorted_proteins))
            representative_entries.append(sorted_proteins[0])

        df = df.copy()
        df['Protein reported by software'] = reported_entries
        df['Leading proteins'] = leading_entries
        df['Representative protein'] = representative_entries
        return df


class FPReader(ResultReader):
    """ Import and preprocess FragPipe result files.

    Attributes:
        filenames_default: (class attribute) Look up of filenames for the
            result files generated by FragPipe with LFQ quantification.
        filenames_isobar: (class attribute) Look up of filenames for the result
            files generated by FragPipe with isobaric quantification.
        sample_column_tags: (class attribute) Column tags for which
            an additional column is present per sample.
        column_mapping: (class attribute) Used to rename original column names
            from FragPipe with the internal standardized names.
        column_tag_mapping: (class attribute) Mapping of 'Old substring' to
            'New substring' that will be replaced in column names. Used to
            rename intensity and spectral count columns.
        protein_info_columns: (class attribute) List of columns that contain
            protein specific information.

        data_directory (str): Location of the MaxQuant 'txt' folder
        contamination_tag (str): Substring present in protein IDs to identify
            them as potential contaminants.
    """

    filenames_default: dict[str, str] = {
        'proteins': 'combined_protein.tsv',
        'peptides': 'combined_peptide.tsv',
        'ions': 'combined_ion.tsv',
    }
    filenames_isobar: dict[str, str] = {
        'proteins': 'protein.tsv',
        'peptides': 'peptide.tsv',
        'ions': 'ion.tsv',
    }
    sample_column_tags: list[str] = [
        'Spectral Count', 'Unique Spectral Count', 'Total Spectral Count',
        'Intensity', 'MaxLFQ Intensity'
    ]
    column_mapping: dict[str, str] = dict([
        ('Combined Total Peptides', 'Total peptides'),  # From LFQ
        ('Total Peptides', 'Total peptides'),  # From TMT
    ])
    column_tag_mapping: OrderedDict[str, str] = OrderedDict([
        ('MaxLFQ Intensity', 'LFQ intensity'),
        ('Total Spectral Count', 'Total spectral count'),
        ('Unique Spectral Count', 'Unique spectral count'),
        ('Spectral Count', 'Spectral count'),
    ])
    protein_info_columns: list[str] = [
        'Protein', 'Protein ID', 'Entry Name', 'Gene',
        'Protein Length', 'Organism', 'Protein Existence',
        'Description', 'Indistinguishable Proteins'
    ]

    def __init__(self, directory: str, isobar: bool = False,
                 contaminant_tag: str = 'contam_') -> None:
        """
        Args:
            directory: Location of the FragPipe result folder
            isobar: True if quantification strategy was TMT, iTRAQ or similar
            contaminant_tag: Prefix of Protein ID entries to identify
                contaminants

        Attributes:
            data_directory: Location of the FragPipe result folder
            filenames: Look up of filenames generated by FragPipe
        """
        self.data_directory: str = directory
        self._isobar: bool = isobar
        self._contaminant_tag: str = contaminant_tag
        if not isobar:
            self.filenames = self.filenames_default
        else:
            self.filenames = self.filenames_isobar

    def import_proteins(self, rename_columns: bool = True,
                        prefix_column_tags: bool = True,
                        rearrange_proteins: bool = True,
                        drop_protein_info: bool = True,
                        special_proteins: list[str] = []) -> pd.DataFrame:
        """ Read and process 'combined_protein.tsv' file.

        Note that is is essential to rename column names before attempting
        to rename sample columns, as the 'Intensity' substring is present in
        multiple columns.
        """
        # Not tested #
        df = self._read_file('proteins')
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        if rearrange_proteins:
            df = self._rearrange_proteins(df, special_proteins)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
        return df

    def import_ions(self, rename_columns: bool = True,
                    prefix_column_tags: bool = True) -> pd.DataFrame:
        """ Read and process 'combined_ion.tsv' file. """
        # Not tested #
        df = self._read_file('ions')
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        df['Protein reported by software'] = df['Protein ID']
        return df

    def _rearrange_proteins(self, df: pd.DataFrame,
                            special_proteins: list[str] = []) -> pd.DataFrame:
        """ Sorts proteins and adds three newcolumns to the dataframe.

        "Leading proteins" contains all protein entries from the "Protein"
        plus "Indistinguishable Proteins" column, which have the same and
        highest number of peptide in the "Peptide counts (all)" column.
        Multiple protein entries are separated by ";". Special proteins are
        listed first and proteins containing the contamination tag are listed
        last. The other proteins are sorted alphabetically ascending.

        "Representative protein" contains only the first entry from the new
        "Leading proteins" column.

        "Protein reported by software" contains the original
        protein id from the "Protein" column.
        """
        sorting_tag_levels = {self._contaminant_tag: 1}
        sorting_tag_levels.update({p: -1 for p in special_proteins})

        reported_entries = []
        leading_entries = []
        representative_entries = []
        for protein_entry, indist_protein_entry in zip(
                df['Protein'], df['Indistinguishable Proteins']):
            protein_entries = [protein_entry]
            if indist_protein_entry:
                for entry in indist_protein_entry.split(', '):
                    protein_entries.append(entry)
            leading_proteins = [p.split('|')[1] for p in protein_entries]

            fastas, sorted_proteins, names = _sort_fasta_entries(
                leading_proteins, sorting_tag_levels
            )
            reported_entries.append(leading_proteins[0])
            leading_entries.append(';'.join(sorted_proteins))
            representative_entries.append(sorted_proteins[0])

        df = df.copy()
        df['Protein reported by software'] = reported_entries
        df['Leading proteins'] = leading_entries
        df['Representative protein'] = representative_entries
        return df


def add_protein_annotations(
        table: pd.DataFrame, fasta_path: str,
        id_column: str = 'Representative protein') -> None:
    """ Adds descriptive columns for the representative protein.

    The added columns always includes "Fasta header", "Protein length",
    "iBAQ peptides", and if possible "Protein entry name" and "Gene id".
    """
    # Not tested #
    protein_db = ProtDB.importProteinDatabase(
        fasta_path, contaminationTag='contam_'
    )

    new_columns = {
        'Representative entry name': [], 'Gene name': [], 'Fasta header': [],
        'Protein length': [], 'iBAQ peptides': [],
    }
    for protein_id in table[id_column]:
        sequence = protein_db[protein_id].sequence
        header_info = protein_db[protein_id].headerInfo

        entry_name = header_info['entry'] if 'entry' in header_info else ''
        gene_name = header_info['gene_id'] if 'gene_id' in header_info else ''
        fasta_header = protein_db[protein_id].fastaHeader
        length = protein_db[protein_id].length()
        ibaq_peptides = helper.calculate_tryptic_ibaq_peptides(sequence)

        new_columns['Representative entry name'].append(entry_name)
        new_columns['Gene name'].append(gene_name)
        new_columns['Fasta header'].append(fasta_header)
        new_columns['Protein length'].append(length)
        new_columns['iBAQ peptides'].append(ibaq_peptides)

    for column in new_columns:
        table[column] = new_columns[column]


def add_sequence_coverage(protein_table: pd.DataFrame,
                          peptide_table: pd.DataFrame,
                          id_column: str = 'Protein reported by software'
                          ) -> None:
    """ Calculates 'Sequence coverage' and adds it to the protein table.

    Requires the columns 'Start' and 'End' in the peptide_table, and
    'Protein length' in the protein_table.
    """
    # Not tested #
    peptide_positions = {}
    for protein_id, pep_group in peptide_table.groupby(by=id_column):
        positions = [(s, e) for s, e in zip(pep_group['Start'], pep_group['End'])]
        peptide_positions[protein_id] = sorted(positions)

    sequence_coverages = []
    for protein_id, protein_length in zip(protein_table[id_column],
                                          protein_table['Protein length']):
        sequence_coverage = helper.calculate_sequence_coverage(
            protein_length, peptide_positions[protein_id], ndigits=1
        )
        sequence_coverages.append(sequence_coverage)
    protein_table['Sequence coverage'] = sequence_coverages


def add_ibaq_intensities(table: pd.DataFrame,
                         normalize_total_intensity: bool = True,
                         peptide_column: str = 'Total peptides',
                         ibaq_peptide_column: str = 'iBAQ peptides',
                         intensity_tag: str = 'Intensity',
                         ibaq_tag: str = 'iBAQ intensity') -> None:
    """ Calculates iBAQ intensities.

    Requires a column containing the theoretical number of iBAQ peptides.
    """
    ibaq_factor = table[peptide_column] / table[ibaq_peptide_column]
    for intensity_column in helper.find_columns(table, intensity_tag):
        ibaq_column = intensity_column.replace(intensity_tag, ibaq_tag)
        table[ibaq_column] = table[intensity_column] * ibaq_factor

        if normalize_total_intensity:
            factor = table[intensity_column].sum() / table[ibaq_column].sum()
            table[ibaq_column] = table[ibaq_column] * factor


def extract_sample_names(df: pd.DataFrame, tag: str) -> list[str]:
    """ Extract sample names from columns containing the 'tag' """
    columns = helper.find_columns(df, tag)
    sample_names = _find_remaining_substrings(columns, tag)
    return sample_names


def _replace_column_tag(df: pd.DataFrame,
                        old_tag: str, new_tag: str) -> pd.DataFrame:
    """ Replace column substrings old_tag with new_tag """
    old_columns = helper.find_columns(df, old_tag)
    new_columns = [c.replace(old_tag, new_tag) for c in old_columns]
    mapping = dict(zip(old_columns, new_columns))
    return df.rename(columns=mapping, inplace=False)


def _rearrange_column_tag(df: pd.DataFrame, tag: str,
                          prefix: bool) -> pd.DataFrame:
    """ Moves the column tag to the beginning or end of each column.

    Args:
        df: Rearrange columns in this DataFrame
        tag: A substring that when found in column names should be moved
            to the beginning or end of the column name
        prefix: if true, the tag string is moved to the beginning of the
            new column names, else to the end.
    """
    old_columns = helper.find_columns(df, tag)
    new_columns = []
    for column_name in old_columns:
        column_name = column_name.replace(tag, '').strip()
        if prefix:
            new_column_name = ' '.join([tag, column_name]).strip()
        else:
            new_column_name = ' '.join([column_name, tag]).strip()
        new_columns.append(new_column_name)
    column_lookup = dict(zip(old_columns, new_columns))
    df = df.rename(columns=column_lookup, inplace=False)
    return df


def _find_remaining_substrings(strings: list[str],
                               split_with: str) -> list[str]:
    """ Find the remaining part from several strings after splitting. """
    substrings = []
    for string in strings:
        substrings.extend([s.strip() for s in string.split(split_with)])
    # Remove empty entries
    substrings = sorted(set(filter(None, substrings)))
    return substrings


def _sort_fasta_entries(fasta_entries: list[str],
                        sorting_tag_levels: dict[str, int] = {}
                        ) -> list[list[str], list[str], list[str]]:
    """ Return sorted fasta headers, protein ids, entry names.

    Fasta headers are first sorted according to the sort level of each header
    in ascending order, and those with the same entries are sorted
    alphabetically according to the UniqueID of the fasta header. By default
    each fasta entry has a sort level of 0.

    Args:
        sorting_tag_levels: Mapping of tags to sort levels. If the tag string
            is present in the UniqueID entry of the fasta headers, the sort
            level of for this fasta header is set.

    Returns:
        sorted lists of [fasta headers, protein ids, entry names]
    """
    values = []
    for fasta in fasta_entries:
        if fasta.count('|') >= 2:
            protein = fasta.split('|')[1]
            name = fasta.split('|')[2].split(' ')[0]
        else:
            protein = fasta
            name = fasta
        sort_level = 0
        for tag, level in sorting_tag_levels.items():
            if tag in protein:
                sort_level = level
        values.append((sort_level, protein, fasta, name))
    values.sort()
    sort_levels, proteins, fastas, names = [list(v) for v in zip(*(values))]
    return fastas, proteins, names


if __name__ == '__main__':
    filedir = 'C:/Users/david.hollenstein/ucloud/python/QuantTable/tests/testdata/maxquant_results'
    protein_table = MQReader(filedir).import_proteins()
    peptide_table = MQReader(filedir).import_peptides()
    sample_names = extract_sample_names(protein_table, 'Intensity')

    filedir = 'C:/Users/david.hollenstein/ucloud/python/QuantTable/tests/testdata/fragpipe_results'
    protein_table = FPReader(filedir).import_proteins()
