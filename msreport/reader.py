""" Module for reading and homogenizing result tables from various MS analysis tools.

Currently MaxQuant and FragPipe protein tables are fully supported, and ion and peptide
tables are partly supported.

New column names:
- Representative protein
- Leading proteins
- Protein reported by software

Unified column names:
- Total peptides
- Spectral count "sample name"
- Unique spectral count "sample name"
- Total spectral count "sample name"
- Intensity "sample name"
- LFQ intensity "sample name"
- iBAQ intensity "sample name"
"""
from collections import OrderedDict
import os
from typing import Optional, Union
import warnings

import numpy as np
import pandas as pd

import msreport.helper as helper


class ResultReader:
    """Base Reader class, is by itself not functional."""

    default_filenames: dict[str, str]
    protected_columns: list[str]
    column_mapping: dict[str, str]
    column_tag_mapping: OrderedDict[str, str]
    sample_column_tags: list[str]

    def __init__(self):
        self.data_directory: str = ""
        self.filenames: dict[str, str] = {}

    def _read_file(self, which: str, sep: str = "\t") -> pd.DataFrame:
        """Read a result table from the data_directory

        Args:
            which: Lookup the filename in self.filenames. If 'which' is not present in
                self.filenames, 'which' is used as the filename.
            sep: Delimiter to use when reading the file
        """
        if which in self.filenames:
            filename = self.filenames[which]
        else:
            filename = which
        filepath = os.path.join(self.data_directory, filename)
        df = pd.read_csv(filepath, sep=sep)
        str_cols = df.select_dtypes(include=["object"]).columns
        df.loc[:, str_cols] = df.loc[:, str_cols].fillna("")
        return df

    def _rename_columns(self, df: pd.DataFrame, prefix_tag: bool) -> pd.DataFrame:
        """Returns a new DataFrame with renamed columns.

        First columns are renamed according to self.column_mapping. Next, tags in
        columns are renamed according to self.column_tag_mapping. Then, for columns
        containing sample names, sample names are and tags are rearranged. Columns from
        self.protected_column_positions are not modified.

        Note that is is essential to rename column names before attempting to rename
        sample columns, as e.g. in FragPipe the "Intensity" substring is present in
        multiple columns.
        """
        new_df = df.copy()

        # Store positions of protected columns
        protected_column_positions = {}
        for col in self.protected_columns:
            if col in new_df.columns:
                protected_column_positions[col] = new_df.columns.get_loc(col)

        # Rename columns
        new_df.rename(columns=self.column_mapping, inplace=True)
        for old_tag, new_tag in self.column_tag_mapping.items():
            new_df.columns = [c.replace(old_tag, new_tag) for c in new_df.columns]

        for tag in self.sample_column_tags:
            # Original columns have already been replaced with new names
            tag = self.column_tag_mapping.get(tag, tag).strip()
            new_df = _rearrange_column_tag(new_df, tag, prefix_tag)

        # Rename protected columns to the original name
        protected_column_mapping = {}
        for col, col_idx in protected_column_positions.items():
            protected_column_mapping[new_df.columns[col_idx]] = col
        new_df.rename(columns=protected_column_mapping, inplace=True)
        return new_df

    def _drop_columns(
        self, df: pd.DataFrame, columns_to_drop: list[str]
    ) -> pd.DataFrame:
        """Returns a new data frame without the specified columns."""
        remaining_columns = []
        for column in df.columns:
            if column not in columns_to_drop:
                remaining_columns.append(column)
        return df[remaining_columns].copy()

    def _drop_columns_by_tag(self, df: pd.DataFrame, tag: str) -> pd.DataFrame:
        """Returns a new data frame without columns containing 'tag'."""
        columns = helper.find_columns(df, tag, must_be_substring=False)
        return self._drop_columns(df, columns)

    def _add_data_directory(self, path) -> None:
        self.data_directory = path


class MQReader(ResultReader):
    """MaxQuant result reader.

    Methods:
        import_proteins: Reads a "proteinGroups.txt" file and returns a processed
            DataFrame, conforming to the MsReport naming conventions.
        import_peptides: Reads a "peptides.txt" file and returns a processed
            DataFrame, conforming to the MsReport naming conventions.

    Attributes:
        default_filenames: (class attribute) Look up of filenames for the result files
            generated by MaxQuant.
        sample_column_tags: (class attribute) Column tags for which an additional column
            is present per sample.
        column_mapping: (class attribute) Used to rename original column names from
            MaxQuant according to the MsReport naming convention.
        column_tag_mapping: (class attribute) Mapping of orignal sample column tags from
            MaxQuant to column tags according to the MsReport naming convention, used to
            replace column names containing the original column tag.
        protein_info_columns: (class attribute) List of columns that contain protein
            specific information. Used to allow removing all protein specific
            information prior to changing the representative protein.
        protein_info_tags: (class attribute) List of tags present in columns that
            contain protein specific information per sample.
        data_directory (str): Location of the MaxQuant "txt" folder
        filenames (list[str]): Look up of filenames generated by MaxQuant
        contamination_tag (str): Substring present in protein IDs to identify them as
            potential contaminants.
    """

    default_filenames: dict[str, str] = {
        "proteins": "proteinGroups.txt",
        "peptides": "peptides.txt",
        "ions": "evidence.txt",
    }
    protected_columns: list[str] = ["iBAQ peptides"]
    sample_column_tags: list[str] = [
        "LFQ intensity",
        "Intensity",
        "iBAQ",
        "MS/MS count",
        "Sequence coverage",
    ]
    column_mapping: dict[str, str] = dict(
        [
            ("Peptides", "Total peptides"),
            ("Sequence coverage [%]", "Sequence coverage"),
        ]
    )
    column_tag_mapping: OrderedDict[str, str] = OrderedDict(
        [("MS/MS count", "Spectral count"), ("iBAQ", "iBAQ intensity")]
    )
    protein_info_columns: list[str] = [
        "Protein names",
        "Gene names",
        "Fasta headers",
        "Sequence coverage [%]",
        "Unique + razor sequence coverage [%]",
        "Unique sequence coverage [%]",
        "Mol. weight [kDa]",
        "Sequence length",
        "Sequence lengths",
        "iBAQ peptides",
    ]
    protein_info_tags: list[str] = ["iBAQ", "Sequence coverage", "site positions"]

    def __init__(
        self, directory: str, isobar: bool = False, contaminant_tag: str = "CON__"
    ) -> None:
        """Initializes the MQReader.

        Args:
            directory: Location of the MaxQuant "txt" folder.
            isobar: Set to True if quantification strategy was TMT, iTRAQ or similar.
            contaminant_tag: Prefix of Protein ID entries to identify contaminants.
        """
        self._add_data_directory(directory)
        self.filenames: dict[str, str] = self.default_filenames
        self._isobar: bool = isobar
        self._contaminant_tag: str = contaminant_tag

    def import_proteins(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        drop_decoy: bool = True,
        drop_idbysite: bool = True,
        sort_proteins: bool = False,
        drop_protein_info: bool = False,
        special_proteins: Optional[list] = None,
    ) -> pd.DataFrame:
        """Reads a "proteinGroups.txt" file and returns a processed DataFrame.

        Adds three new protein entry columns to comply with the MsReport conventions:
        "Protein reported by software", "Leading proteins", "Representative protein".

        "Protein reported by software" contains the first protein ID from the "Majority
        protein IDs" column. "Leading proteins" contain all entries from the "Majority
        protein IDs" column that have the same and highest number of mapped peptides in
        the "Peptide counts (all)" column, multiple protein entries are separated by
        ";". "Representative protein" contains the first entry form "Leading proteins".

        If 'sort_proteins' is enabled, the order of "Leading proteins" entries may
        change, resulting in a different "Representative protein" entry. Several
        columns in the "proteinGroups.txt" file contain information specific for the
        first entry of the "Majority protein IDs" column. When using 'sort_proteins', it
        is therefore recommanded to remove all columns containing protein specific
        information by enabling 'drop_protein_info'.

        Args:
            filename: allows specifying an alternative filename, otherwise the default
                filename is used.
            rename_columns: If True, columns are renamed according to the MsReport
                conventions; default True.
            prefix_column_tags: If True, column tags such as "Intensity" are added
                in front of the sample names, e.g. "Intensity sample_name". If False,
                column tags are added afterwards, e.g. "Sample_name Intensity"; default
                True.
            drop_decoy: If True, decoy entries are removed; default True.
            drop_idbysite: If True, protein groups that were only identified by site are
                removed; default True.
            sort_proteins: If True, protein entries in "Leading proteins" are sorted
                alphabetically ascending, with the exception that decoy proteins are
                always sorted to the back and special proteins are sorted to the front.
                Default False.
            drop_protein_info: If True, columns containing protein specific information,
                such as "Gene names", "Sequence coverage [%]" or "iBAQ peptides". See
                MQReader.protein_info_columns and MQReader.protein_info_tags for the
                full list of columns that will be removed. Default False.
            special_proteins: Optional, allows specifying a list of protein IDs that
                will always be sorted to the beginning of the "Leading proteins" and
                thus be used as "Representative protein" when 'sort_proteins' is
                enabled.

        Returns:
            A DataFrame containing the processed protein table.
        """
        df = self._read_file("proteins" if filename is None else filename)
        df = self._add_protein_entries(df, sort_proteins, special_proteins)

        if drop_decoy:
            df = self._drop_decoy(df)
        if drop_idbysite:
            df = self._drop_idbysite(df)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
            for tag in self.protein_info_tags:
                df = self._drop_columns_by_tag(df, tag)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def import_peptides(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        drop_decoy: bool = True,
    ) -> pd.DataFrame:
        """Reads a "peptides.txt" file and returns a processed DataFrame.

        Args:
            filename: allows specifying an alternative filename, otherwise the default
                filename is used.
            rename_columns: If True, columns are renamed according to the MsReport
                conventions; default True.
            prefix_column_tags: If True, column tags such as "Intensity" are added
                in front of the sample names, e.g. "Intensity sample_name". If False,
                column tags are added afterwards, e.g. "Sample_name Intensity"; default
                True.
            drop_decoy: If True, decoy entries are removed; default True.

        Returns:
            A DataFrame containing the processed peptide table.
        """
        raise NotImplementedError("Needs to be reimplemented")
        df = self._read_file("peptides" if filename is None else filename)
        # df = self._add_protein_entries(df)
        # Note that _add_protein_entries would need to be adapted for the peptide table.
        if drop_decoy:
            df = self._drop_decoy(df)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def import_ions(
        self, filename: Optional[str] = None, drop_decoy: bool = True
    ) -> pd.DataFrame:
        """Reads an "evidence.txt" file and returns a processed DataFrame.

        Args:
            filename: allows specifying an alternative filename, otherwise the default
                filename is used.
            drop_decoy: If True, decoy entries are removed; default True.

        Returns:
            A DataFrame containing the processed ion table.
        """
        raise NotImplementedError("Needs to be reimplemented")
        df = self._read_file("ions")
        if drop_decoy:
            df = self._drop_decoy(df)
        return df

    def _add_protein_entries(
        self,
        df: pd.DataFrame,
        sort_proteins: bool = False,
        special_proteins: Optional[list] = None,
    ) -> pd.DataFrame:
        """Adds standardized protein entry columns to the data frame.

        Adds new columns to comply with the MsReport conventions. "Protein reported by
        software" contains the first protein ID from the "Majority protein IDs" column.
        "Leading proteins" contain all entries from the "Majority protein IDs" column
        that have the same and highest number of mapped peptides in the "Peptide counts
        (all)" column, multiple protein entries are separated by ";". "Representative
        protein" contains the first entry form "Leading proteins". "Potential
        contaminant" contains boolean values.

        Args:
            df: DataFrame containing a MaxQuant result table.
            sort_proteins: If True, protein entries in "Leading proteins" are sorted
                alphabetically ascending, with the exception that decoy proteins are
                always sorted to the back and special proteins are sorted to the front.
                Default False.
            special_proteins: Optional, allows specifying a list of protein IDs that
                will always be sorted to the beginning of the "Leading proteins" and
                thus be used as "Representative protein" when 'sort_proteins' is
                enabled.
        """
        # NOTE: not tested directly, only via integration #
        leading_protein_entries = self._collect_leading_protein_entries(df)
        protein_entry_table = _process_protein_entries(
            leading_protein_entries,
            self._contaminant_tag,
            sort_proteins,
            special_proteins,
        )
        for key in protein_entry_table:
            df[key] = protein_entry_table[key]
        return df

    def _collect_leading_protein_entries(self, df: pd.DataFrame) -> list[list[str]]:
        """Generates a list of leading proteins from the "Majority protein IDs" column.

        Each entry in the list contains a list of all entries from the "Majority
        protein IDs" column that have the same and highest number of mapped peptides in
        the "Peptide counts (all)" column.

        Can only be used for "proteinGroups.txt" tables.

        Args:
            df: DataFrame containing a "proteinGroups.txt" table.

        Returns:
            A list of the same length as the input DataFrame. Each position contains a
            list of leading protein entries, which a minimum of one entry.
        """
        leading_protein_entries = []
        for majority_ids_entry, count_entry in zip(
            df["Majority protein IDs"], df["Peptide counts (all)"]
        ):
            proteins = majority_ids_entry.split(";")
            counts = [int(i) for i in count_entry.split(";")]
            highest_count = max(counts)
            protein_entries = [
                f for f, c in zip(proteins, counts) if c >= highest_count
            ]
            leading_protein_entries.append(protein_entries)
        return leading_protein_entries

    def _drop_decoy(self, df: pd.DataFrame) -> pd.DataFrame:
        """Returns a DataFrame not containing decoy entries."""
        return df.loc[df["Reverse"] != "+"]

    def _drop_idbysite(self, df: pd.DataFrame) -> pd.DataFrame:
        """Returns a DataFrame not containing entries only identified by site."""
        return df.loc[df["Only identified by site"] != "+"]


class FPReader(ResultReader):
    """FragPipe result reader.

    Methods:
        import_proteins: Reads a "combined_protein.tsv" or "protein.tsv" file and
            returns a processed DataFrame, conforming to the MsReport naming
            conventions.
        import_peptides: Reads a "combined_peptide.tsv" or "peptide.tsv" file and
            returns a processed DataFrame, conforming to the MsReport naming
            conventions.
        import_ions: Reads a "combined_ion.tsv" or "ion.tsv" file and returns a
            processed DataFrame, conforming to the MsReport naming conventions.

    Attributes:
        default_filenames: (class attribute) Look up of default filenames of the result
            files generated by FragPipe.
        isobar_filenames: (class attribute) Look up of default filenames of the result
            files generated by FragPipe, which are relevant when using isobaric
            quantification.
        sample_column_tags: (class attribute) Tags (column name substrings) that
            idenfity sample columns. Sample columns are those, for which one unique
            column is present per sample, for example intensity columns.
        column_mapping: (class attribute) Used to rename original column names from
            FragPipe according to the MsReport naming convention.
        column_tag_mapping: (class attribute) Mapping of orignal sample column tags from
            FragPipe to column tags according to the MsReport naming convention, used to
            replace column names containing the original column tag.
        protein_info_columns: (class attribute) List of columns that contain information
            specific to the leading protein.
        protein_info_tags: (class attribute) List of substrings present in columns that
            contain information specific to the leading protein.
        data_directory (str): Location of the folder containing FragPipe result files.
        filenames (dict[str, str]): Look up of FragPipe result filenames used for
            importing protein or other tables.
        contamination_tag (str): Substring present in protein IDs to identify them as
            potential contaminants.
    """

    default_filenames: dict[str, str] = {
        "proteins": "combined_protein.tsv",
        "peptides": "combined_peptide.tsv",
        "ions": "combined_ion.tsv",
    }
    isobar_filenames: dict[str, str] = {
        "proteins": "protein.tsv",
        "peptides": "peptide.tsv",
        "ions": "ion.tsv",
    }
    protected_columns: list[str] = []
    sample_column_tags: list[str] = [
        "Spectral Count",
        "Unique Spectral Count",
        "Total Spectral Count",
        "Intensity",
        "MaxLFQ Intensity",
    ]
    column_mapping: dict[str, str] = dict(
        [
            ("Combined Total Peptides", "Total peptides"),  # From LFQ
            ("Total Peptides", "Total peptides"),  # From TMT
        ]
    )
    column_tag_mapping: OrderedDict[str, str] = OrderedDict(
        [
            ("MaxLFQ Intensity", "LFQ intensity"),
            ("Total Spectral Count", "Total spectral count"),
            ("Unique Spectral Count", "Unique spectral count"),
            ("Spectral Count", "Spectral count"),
        ]
    )
    protein_info_columns: list[str] = [
        "Protein",
        "Protein ID",
        "Entry Name",
        "Gene",
        "Protein Length",
        "Organism",
        "Protein Existence",
        "Description",
        "Indistinguishable Proteins",
    ]
    protein_info_tags: list[str] = []

    def __init__(
        self, directory: str, isobar: bool = False, contaminant_tag: str = "contam_"
    ) -> None:
        """Initializes the FPReader.

        Args:
            directory: Location of the FragPipe result folder
            isobar: Set to True if quantification strategy was TMT, iTRAQ or similar;
                default False.
            contaminant_tag: Prefix of Protein ID entries to identify contaminants;
                default "contam_".
        """
        self._add_data_directory(directory)
        self._isobar: bool = isobar
        self._contaminant_tag: str = contaminant_tag
        if not isobar:
            self.filenames = self.default_filenames
        else:
            self.filenames = self.isobar_filenames

    def import_proteins(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        sort_proteins: bool = False,
        drop_protein_info: bool = False,
        special_proteins: list[str] = [],
    ) -> pd.DataFrame:
        """Reads a "combined_protein.tsv" or "protein.tsv" file and returns a processed
        DataFrame.

        Adds four protein entry columns to comply with the MsReport conventions:
        "Protein reported by software", "Leading proteins", "Representative protein",
        "Potential contaminant".

        "Protein reported by software" contains the protein ID extracted from the
        "Protein" column. "Leading proteins" contains the combined protein IDs extracted
        from the "Protein" and "Indistinguishable Proteins" columns, multiple entries
        are separated by ";". "Representative protein" contains the first entry form
        "Leading proteins".

        If 'sort_proteins' is enabled, the order of "Leading proteins" entries may
        change, resulting in a different "Representative protein" entry. Several
        columns in the "combined_protein.tsv" file contain information specific for the
        protein entry of the "Protein" column. When using 'sort_proteins', it is
        therefore recommanded to remove all columns containing protein specific
        information by enabling 'drop_protein_info'.

        Args:
            filename: Allows specifying an alternative filename, otherwise the default
                filename is used.
            rename_columns: If True, columns are renamed according to the MsReport
                conventions; default True.
            prefix_column_tags: If True, column tags such as "Intensity" are added
                in front of the sample names, e.g. "Intensity sample_name". If False,
                column tags are added afterwards, e.g. "Sample_name Intensity"; default
                True.
            sort_proteins: If True, protein entries in "Leading proteins" are sorted
                alphabetically ascending, with the exception that decoy proteins are
                always sorted to the back and special proteins are sorted to the front.
                Default False.
            drop_protein_info: If True, columns containing protein specific information,
                such as "Gene" or "Protein Length". See FPReader.protein_info_columns
                and FPReader.protein_info_tags for the full list of columns that will be
                removed. Default False.
            special_proteins: Optional, allows specifying a list of protein IDs that
                will always be sorted to the beginning of the "Leading proteins" and
                thus be used as "Representative protein" when 'sort_proteins' is
                enabled.

        Returns:
            A DataFrame containing the processed protein table.
        """
        # TODO: not tested
        df = self._read_file("proteins" if filename is None else filename)
        df = self._add_protein_entries(df, sort_proteins, special_proteins)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
            for tag in self.protein_info_tags:
                df = self._drop_columns_by_tag(df, tag)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def import_ions(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
    ) -> pd.DataFrame:
        """Reads a "combined_ion.tsv" or "ion.tsv" file and returns a processed
        DataFrame.

        Adds the columns "Representative protein" and "Protein reported by software".
        Note that the function is only partially implemented and should only be used to
        allow the calculation of protein sequence coverage.

        Args:
            filename: Allows specifying an alternative filename, otherwise the default
                filename is used.
            rename_columns: If True, columns are renamed according to the MsReport
                conventions; default True.
            prefix_column_tags: If True, column tags such as "Intensity" are added
                in front of the sample names, e.g. "Intensity sample_name". If False,
                column tags are added afterwards, e.g. "Sample_name Intensity"; default
                True.
        """
        # TODO: not tested #
        warnings.warn(
            "This function is only partially implemented.",
            UserWarning,
            stacklevel=2,
        )

        df = self._read_file("ions" if filename is None else filename)

        # FUTURE: replace this by _add_protein_entries(df, False) if FragPipe adds
        #         'Indistinguishable Proteins' to the ion table.
        df["Representative protein"] = df["Protein ID"]
        df["Protein reported by software"] = df["Protein ID"]

        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def _add_protein_entries(
        self,
        df: pd.DataFrame,
        sort_proteins: bool,
        special_proteins: Optional[list] = None,
    ) -> pd.DataFrame:
        """Adds standardized protein entry columns to the data frame.

        Adds new columns to comply with the MsReport conventions. "Protein reported by
        software" contains the protein ID extracted from the "Protein" column. "Leading
        proteins" contains the combined protein IDs extracted from the "Protein" and
        "Indistinguishable Proteins" columns, multiple entries are separated by ";".
        "Representative protein" contains the first entry form "Leading proteins".
        "Potential contaminant" contains boolean values.

        Args:
            df: DataFrame containing a FragPipe result table.
            sort_proteins: If True, protein entries in "Leading proteins" are sorted
                alphabetically ascending, with the exception that decoy proteins are
                always sorted to the back and special proteins are sorted to the front.
                Default False.
            special_proteins: Optional, allows specifying a list of protein IDs that
                will always be sorted to the beginning of the "Leading proteins" and
                thus be used as "Representative protein" when 'sort_proteins' is
                enabled.

        Returns:
            A copy of the input DataFrame, containing the additional protein columns.
        """
        leading_protein_entries = self._collect_leading_protein_entries(df)
        protein_entry_table = _process_protein_entries(
            leading_protein_entries,
            self._contaminant_tag,
            sort_proteins,
            special_proteins,
        )
        for key in protein_entry_table:
            df[key] = protein_entry_table[key]
        return df

    def _collect_leading_protein_entries(self, df: pd.DataFrame) -> list[list[str]]:
        """Generates a list of leading protein entries.

        Each entry in the list contains a list of all entries from the "Protein" and
        "Indistinguishable Proteins" columns.

        Can only be used for "combined_protein.tsv" and "protein.tsv" tables.

        Args:
            df: DataFrame containing a protein table.

        Returns:
            A list of the same length as the input DataFrame. Each position contains a
            list of leading protein entries, which a minimum of one entry.
        """
        leading_protein_entries = []
        for protein_entry, indist_protein_entry in zip(
            df["Protein"], df["Indistinguishable Proteins"]
        ):
            protein_entries = [protein_entry]
            if indist_protein_entry:
                for entry in indist_protein_entry.split(", "):
                    protein_entries.append(entry)
            leading_protein_entries.append(protein_entries)
        return leading_protein_entries


class SpectronautReader(ResultReader):
    """Spectronaut DIA result reader.

    Methods:
        import_proteins: Reads a Spectronaut report file and returns a processed
            DataFrame, conforming to the MsReport naming conventions.
    """

    protected_columns: list[str] = []
    column_mapping: dict[str, str] = dict(
        [
            ("PG.Cscore", "Protein cscore"),
            ("PG.NrOfStrippedSequencesIdentified (Experiment-wide)", "Total peptides"),
            ("PG.NrOfPrecursorsIdentified (Experiment-wide)", "Total ions"),
            ("PG.Cscore", "Cscore"),
        ]
    )
    sample_column_tags: list[str] = [
        ".PG.NrOfPrecursorsIdentified",
        ".PG.IBAQ",
        ".PG.Quantity",
        ".PG.NrOfPrecursorsUsedForQuantification",
        ".PG.NrOfStrippedSequencesUsedForQuantification",
    ]
    column_tag_mapping: OrderedDict[str, str] = OrderedDict(
        [
            (".PG.NrOfPrecursorsIdentified", " Ion count"),
            (".PG.IBAQ", " iBAQ intensity"),
            (".PG.Quantity", " Intensity"),
            (".PG.NrOfPrecursorsUsedForQuantification", " Quantified ion count"),
            (
                ".PG.NrOfStrippedSequencesUsedForQuantification",
                " Total quantified peptides",
            ),
        ]
    )
    protein_info_columns: list[str] = [
        "PG.ProteinGroups",
        "PG.ProteinAccessions",
        "PG.Genes",
        "PG.Organisms",
        "PG.ProteinDescriptions",
        "PG.UniProtIds",
        "PG.ProteinNames",
        "PG.FastaHeaders",
        "PG.OrganismId",
        "PG.MolecularWeight",
    ]
    protein_info_tags: list[str] = []

    def __init__(self, directory: str, contaminant_tag: str = "contam_") -> None:
        """Initializes the SpectronautReader.

        Args:
            directory: Location of the Spectronaut result folder.
            contaminant_tag: Prefix of Protein ID entries to identify contaminants;
                default "contam_".
        """
        warnings.warn(
            "The SpectronautReader is still in development and only partially functional.",
            UserWarning,
            stacklevel=2,
        )

        self._add_data_directory(directory)
        self._contaminant_tag: str = contaminant_tag
        self.filenames: dict[str, str] = {}
        self.design: Optional[pd.DataFrame] = None
        self._import_spectronaut_design()

    def import_proteins(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        sort_proteins: bool = True,
        drop_protein_info: bool = True,
        special_proteins: list[str] = [],
    ) -> pd.DataFrame:
        """Reads a Spectronaut protein report file and returns a processed DataFrame.

        Adds four protein entry columns to comply with the MsReport conventions:
        "Protein reported by software", "Leading proteins", "Representative protein",
        "Potential contaminant".

        "Protein reported by software" contains the first entry from the
        "PG.ProteinAccessions" column. "Leading proteins" contains all entries from the
        "PG.ProteinAccessions" column, multiple entries are separated by ";".
        "Representative protein" contains the first entry form "Leading proteins".

        If 'sort_proteins' is enabled, the order of "Leading proteins" entries may
        change, resulting in a different "Representative protein" entry. Several
        columns in the "combined_protein.tsv" file contain information specific for the
        protein entry of the "Protein" column. When using 'sort_proteins', it is
        therefore recommanded to remove all columns containing protein specific
        information by enabling 'drop_protein_info'.

        Args:
            filename: Allows specifying an alternative filename, otherwise the default
                filename is used.
            rename_columns: If True, columns are renamed according to the MsReport
                conventions; default True.
            prefix_column_tags: If True, column tags such as "Intensity" are added
                in front of the sample names, e.g. "Intensity sample_name". If False,
                column tags are added afterwards, e.g. "Sample_name Intensity"; default
                True.
            sort_proteins: If True, protein entries in "Leading proteins" are sorted
                alphabetically ascending, with the exception that decoy proteins are
                always sorted to the back and special proteins are sorted to the front.
                Default False.
            drop_protein_info: If True, columns containing protein specific information,
                such as "Gene" or "Protein Length". See
                SpectronautReader.protein_info_columns and
                SpectronautReader.protein_info_tags for the full list of columns that
                will be removed. Default False.
            special_proteins: Optional, allows specifying a list of protein IDs that
                will always be sorted to the beginning of the "Leading proteins" and
                thus be used as "Representative protein" when 'sort_proteins' is
                enabled.

        Returns:
            A DataFrame containing the processed protein table.
        """
        # Find report filename
        if filename is None:
            # For now, simply look for a file that ends with report.X (X=xls, tsv, csv)
            report_endings = ["report.xls", "report.tsv", "report.csv"]
            matched_filenames = []
            for filename in os.listdir(self.data_directory):
                if any([filename.lower().endswith(s) for s in report_endings]):
                    matched_filenames.append(filename)
            filename = matched_filenames[0]

        df = self._read_file(filename)
        df = self._tidy_up_sample_columns(df)
        df = self._add_protein_entries(df, sort_proteins, special_proteins)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
            for tag in self.protein_info_tags:
                df = self._drop_columns_by_tag(df, tag)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def _import_spectronaut_design(self):
        """TODO add docstring."""
        report_endings = [f"conditionsetup{s}" for s in (".xls", ".tsv", ".csv")]
        matched_filenames = []
        for filename in os.listdir(self.data_directory):
            if any([filename.lower().endswith(s) for s in report_endings]):
                matched_filenames.append(filename)
        if matched_filenames:
            filename = matched_filenames[0]
            condition_setup = self._read_file(filename)

            condition_setup["Sample"] = (
                condition_setup["Condition"]
                + "_"
                + condition_setup["Replicate"].astype(str)
            )
            self.design = pd.DataFrame(
                {
                    "Sample": condition_setup["Sample"],
                    "Experiment": condition_setup["Condition"],
                    "File name": condition_setup["File Name"],
                    "Run label": condition_setup["Run Label"],
                }
            )
        else:
            self.design = None

    def _add_protein_entries(
        self,
        df: pd.DataFrame,
        sort_proteins: bool = False,
        special_proteins: Optional[list] = None,
    ) -> pd.DataFrame:
        """Adds standardized protein entry columns to the data frame.

        Added columns are "Leading proteins", "Representative protein", and "Protein
        reported by software".

        TODO: Docstring needs expansion for sorting, contaminants and special proteins
        """
        # not tested directly, only via integration #
        leading_protein_entries = self._collect_leading_protein_entries(df)
        protein_entry_table = _process_protein_entries(
            leading_protein_entries,
            self._contaminant_tag,
            sort_proteins,
            special_proteins,
        )
        for key in protein_entry_table:
            df[key] = protein_entry_table[key]
        return df

    def _collect_leading_protein_entries(self, df: pd.DataFrame) -> list[list[str]]:
        """TODO add docstring"""
        leading_protein_entries = [
            entries.split(";") for entries in df["PG.ProteinAccessions"]
        ]
        return leading_protein_entries

    def _tidy_up_sample_columns(self, df):
        df = df.copy()
        columns = df.columns
        with warnings.catch_warnings():
            warnings.simplefilter(action="ignore", category=FutureWarning)

            # Remove leading brackets
            columns = columns.str.replace(r"^\[[0-9]+\] ", "")
            # Replace Spectronaut run labels with sample names
            if self.design is not None:
                for sample, label in zip(
                    self.design["Sample"], self.design["Run label"]
                ):
                    columns = columns.str.replace(label, sample)
            df.columns = columns
        return df


def add_protein_annotations(
    table: pd.DataFrame,
    fasta_path: Union[str, list[str]],
    id_column: str = "Representative protein",
) -> None:
    """Reads a fasta file and adds protein annotation columns to the 'table'.

    The added columns always include "Fasta header", "Protein length", "iBAQ peptides",
    and if possible "Protein entry name" and "Gene name". The number of "iBAQ peptides"
    is calculated as the number of tryptic peptides with a length between 7 and 30 amino
    acids.

    Args:
        table: DataFrame to which the protein annotations are added.
        fasta_path: Path of a fasta file, or a list of fasta file paths.
        id_column: Column in 'table' that contains protein IDs that are used to find
            matching entries in the fasta files.
    """
    # not tested #
    if isinstance(fasta_path, str):
        fasta_paths = [fasta_path]
    else:
        fasta_paths = fasta_path

    protein_db = None
    for path in fasta_paths:
        protein_db = helper.importProteinDatabase(path, database=protein_db)

    new_columns = {
        "Protein entry name": [],
        "Gene name": [],
        "Fasta header": [],
        "Protein length": [],
        "iBAQ peptides": [],
    }
    for protein_id in table[id_column]:
        if protein_id in protein_db.proteins:
            sequence = protein_db[protein_id].sequence
            header_info = protein_db[protein_id].headerInfo

            entry_name = header_info["entry"] if "entry" in header_info else ""
            gene_name = header_info["GN"] if "GN" in header_info else ""
            fasta_header = protein_db[protein_id].fastaHeader
            length = protein_db[protein_id].length()
            ibaq_peptides = helper.calculate_tryptic_ibaq_peptides(sequence)
        else:
            entry_name = ""
            gene_name = ""
            fasta_header = ""
            length = np.nan
            ibaq_peptides = np.nan

        new_columns["Protein entry name"].append(entry_name)
        new_columns["Gene name"].append(gene_name)
        new_columns["Fasta header"].append(fasta_header)
        new_columns["Protein length"].append(length)
        new_columns["iBAQ peptides"].append(ibaq_peptides)

    for column in new_columns:
        table[column] = new_columns[column]


def add_sequence_coverage(
    protein_table: pd.DataFrame,
    peptide_table: pd.DataFrame,
    id_column: str = "Protein reported by software",
) -> None:
    """Calculates "Sequence coverage" and adds a new column to the 'protein_table'.

    Sequence coverage is represented as a percentage, with values ranging from 0 to 100.
    Requires the columns "Start" and "End" in the 'peptide_table', and "Protein length"
    in the 'protein_table'.

    Args:
        protein_table: DataFrame to which the "Sequence coverage" column is added.
        peptide_table: DataFrame which contains peptide information required for
            calculation of the protein sequence coverage.
        id_column: Column used to match entries between the 'protein_table' and the
            'peptide_table', must be present in both tables. Default
            "Protein reported by software".
    """
    # not tested #
    peptide_positions = {}
    for protein_id, peptide_group in peptide_table.groupby(by=id_column):
        positions = [
            (s, e) for s, e in zip(peptide_group["Start"], peptide_group["End"])
        ]
        peptide_positions[protein_id] = sorted(positions)

    sequence_coverages = []
    for protein_id, protein_length in zip(
        protein_table[id_column], protein_table["Protein length"]
    ):
        sequence_coverage = helper.calculate_sequence_coverage(
            protein_length, peptide_positions[protein_id], ndigits=1
        )
        sequence_coverages.append(sequence_coverage)
    protein_table["Sequence coverage"] = sequence_coverages


def add_ibaq_intensities(
    table: pd.DataFrame,
    normalize: bool = True,
    ibaq_peptide_column: str = "iBAQ peptides",
    intensity_tag: str = "Intensity",
    ibaq_tag: str = "iBAQ intensity",
) -> None:
    """Adds iBAQ intensitiy columns to the 'table'.

    Requires a column containing the theoretical number of iBAQ peptides.

    Args:
        table: DataFrame to which the iBAQ intensity columns are added.
        normalize: Scales iBAQ intensities per sample so that the sum of all iBAQ
            intensities is equal to the sum of all Intensities.
        ibaq_peptide_column: Column in 'table' containing the number of iBAQ peptides.
        intensity_tag: Substring used to identify intensity columns from the 'table'
            that are used to calculate iBAQ intensities.
        ibaq_tag: Substring used for naming the new 'table' columns containing the
            calculated iBAQ intensities. The column names are generated by replacing
            the 'intensity_tag' with the 'ibaq_tag'.
    """
    for intensity_column in helper.find_columns(table, intensity_tag):
        ibaq_column = intensity_column.replace(intensity_tag, ibaq_tag)
        table[ibaq_column] = table[intensity_column] / table[ibaq_peptide_column]

        if normalize:
            factor = table[intensity_column].sum() / table[ibaq_column].sum()
            table[ibaq_column] = table[ibaq_column] * factor


def add_peptide_positions(
    table: pd.DataFrame,
    fasta_path: Union[str, list[str]],
    peptide_column: str = "Peptide Sequence",
    protein_column: str = "Representative protein",
) -> None:
    """Adds peptide "Start" and "End" positions to the table.

    Args:
        table: DataFrame to which the protein annotations are added.
        fasta_path: Path of a fasta file, or a list of fasta file paths.
        peptide_column: Column in 'table' that contains the peptide sequence. Peptide
            sequences must only contain amino acids and no other symbols.
        protein_column: Column in 'table' that contains protein IDs that are used to
            find matching entries in the fasta files.
    """
    # not tested #
    if isinstance(fasta_path, str):
        fasta_paths = [fasta_path]
    else:
        fasta_paths = fasta_path

    protein_db = None
    for path in fasta_paths:
        protein_db = helper.importProteinDatabase(path, database=protein_db)

    peptide_positions = {"Start": [], "End": []}
    for peptide, protein_id in zip(table[peptide_column], table[protein_column]):
        sequence = protein_db[protein_id].sequence
        start = sequence.find(peptide) + 1
        end = start + len(peptide) - 1
        if start == 0:
            start, end = -1, -1
        peptide_positions["Start"].append(start)
        peptide_positions["End"].append(end)

    for key in peptide_positions:
        table[key] = peptide_positions[key]


def propagate_representative_protein(
    target_table: pd.DataFrame, source_table: pd.DataFrame
) -> None:
    """Propagates "Representative protein" column from the source to the target table.

    The column "Protein reported by software" is used to match entries between the two
    tables. Then entries from "Representative protein" are propageted from the
    'source_table' to matching rows in the 'target_table'.

    Args:
        target_table: DataFrame to which "Representative protein" entries will be added.
        source_table: DataFrame from which "Representative protein" entries are
            propagated.
    """
    # not tested #
    protein_lookup = {}
    for old, new in zip(
        source_table["Protein reported by software"],
        source_table["Representative protein"],
    ):
        protein_lookup[old] = new

    new_protein_ids = []
    for old in target_table["Protein reported by software"]:
        new_protein_ids.append(protein_lookup[old])
    target_table["Representative protein"] = new_protein_ids


def extract_sample_names(df: pd.DataFrame, tag: str) -> list[str]:
    """Extracts sample names from columns containing the 'tag' substring.

    Sample names are extracted from column names containing the 'tag' string, by
    splitting the column name with the 'tag', and removing all trailing and leading
    white spaces from the resulting strings.

    Args:
        df: Column names from this DataFrame are used for extracting sample names.
        tag: Column names containing the 'tag' are selected for extracting sample names.

    Returns:
        A list of sample names.
    """
    columns = helper.find_columns(df, tag)
    sample_names = _find_remaining_substrings(columns, tag)
    return sample_names


def _rearrange_column_tag(df: pd.DataFrame, tag: str, prefix: bool) -> pd.DataFrame:
    """Moves the column 'tag' to the beginning or end of each column name.

    Args:
        df: Rearrange columns in this DataFrame
        tag: A substring that when found in column names should be moved to the
            beginning or end of the column name
        prefix: If true, the tag string is moved to the beginning of the new column
            names, else to the end.
    """
    old_columns = helper.find_columns(df, tag)
    new_columns = []
    for column_name in old_columns:
        column_name = column_name.replace(tag, "").strip()
        if prefix:
            new_column_name = " ".join([tag, column_name]).strip()
        else:
            new_column_name = " ".join([column_name, tag]).strip()
        new_columns.append(new_column_name)
    column_lookup = dict(zip(old_columns, new_columns))
    df = df.rename(columns=column_lookup, inplace=False)
    return df


def _find_remaining_substrings(strings: list[str], split_with: str) -> list[str]:
    """Finds the remaining part from several strings after splitting."""
    substrings = []
    for string in strings:
        substrings.extend([s.strip() for s in string.split(split_with)])
    # Remove empty entries
    substrings = sorted(set(filter(None, substrings)))
    return substrings


def _sort_leading_proteins(
    df: pd.DataFrame,
    contaminant_tag: Optional[str] = None,
    special_proteins: list[str] = [],
) -> pd.DataFrame:
    """Sorts protein entries from the 'Leading proteins' column.

    Multiple entries in the 'Leading proteins' column must be separated by ';'. After
    sorting, special proteins are listed first and proteins containing the
    contamination tag are listed last. The other proteins are sorted alphabetically
    ascending.

    The first entry from the sorted 'Leading proteins' is written into the
    'Representative protein' column.

    Args:
        df: DataFrame that contains protein entries for sorting.
        contaminant_tag: Optional, if specified protein entries containing the
            'contaminant_tag' are considered as contaminants.
        special_proteins: Optional, a list of special proteins.

    Returns:
        A copy of the 'df' DataFrame, with entries in the "Leading proteins" column
        being sorted and the first leading protein entry written into the
        "Representative protein" columns.
    """
    sorting_tag_levels = {}
    if contaminant_tag is not None:
        sorting_tag_levels[contaminant_tag] = 1
    sorting_tag_levels.update({p: -1 for p in special_proteins})

    leading_entries = []
    representative_entries = []
    for leading_proteins in df["Leading proteins"]:
        proteins = leading_proteins.split(";")
        fastas, sorted_proteins, names = _sort_fasta_entries(
            proteins, sorting_tag_levels
        )
        representative_entries.append(sorted_proteins[0])
        leading_entries.append(";".join(sorted_proteins))

    df = df.copy()
    df["Representative protein"] = representative_entries
    df["Leading proteins"] = leading_entries
    return df


def _sort_proteins_and_contaminants(
    proteins: list[str],
    contaminants: Optional[list[bool]] = None,
    special_proteins: Optional[list[str]] = None,
) -> tuple[list[str], list[bool]]:
    """Sorts protein and contaminant entries.

    Proteins that are in the list of special proteins are listed first, then normal
    proteins and finally contaminants. Then each group is sorted alphabetically.

    Args:
        proteins: List of protein names to be sorted.
        contaminants: Optional, a list of booleans that indicate whether a protein is a
            contaminant or not.
        special_proteins: Optional, a list of special proteins.

    Returns:
        Sorted copies of the 'proteins' and 'contaminants' lists. If 'contaminants' was
        not specified, all entries in the returned 'contaminants' will be None.
    """
    if contaminants is not None:
        sorting = [int(is_contaminant) for is_contaminant in contaminants]
    else:
        contaminants = [None for p in proteins]
        sorting = [0 for p in proteins]

    if special_proteins is not None:
        _sorting = []
        for p, sort_level in zip(proteins, sorting):
            _sorting.append(sort_level + (-2 if p in special_proteins else 0))
        sorting = _sorting

    sorted_values = sorted(zip(sorting, proteins, contaminants))
    _, proteins, contaminants = [list(v) for v in zip(*(sorted_values))]
    return proteins, contaminants


def _sort_fasta_entries(
    fasta_entries: list[str], sorting_tag_levels: dict[str, int] = {}
) -> tuple[list[str], list[str], list[str]]:
    """Return sorted fasta headers, protein ids, and entry names.

    Fasta headers are first sorted according to the sort level of each header in
    ascending order, and those with the same entries are sorted alphabetically
    according to the UniqueID of the fasta header. By default each fasta entry has a
    sort level of 0.

    Args:
        fasta_entries: A list of fasta headers, or fasta header like strings.
        sorting_tag_levels: Mapping of tags to sort levels. If the tag string is present
            in the UniqueID entry of the fasta headers, the sort level of this tag is
            used.

    Returns:
        Sorted lists of (fasta headers, protein ids, entry names)
    """
    values = []
    for fasta in fasta_entries:
        if fasta.count("|") >= 2:
            protein = fasta.split("|")[1]
            name = fasta.split("|")[2].split(" ")[0]
        else:
            protein = fasta
            name = fasta
        sort_level = 0
        for tag, level in sorting_tag_levels.items():
            if tag in protein:
                sort_level = level
        values.append((sort_level, protein, fasta, name))
    values.sort()
    sort_levels, proteins, fastas, names = [list(v) for v in zip(*(values))]
    return fastas, proteins, names


def _add_potential_contaminants(df: pd.DataFrame, contaminant_tag: str) -> pd.DataFrame:
    """Adds a "Potential contaminant" column to the data frame.

    "Potential contaminant" will be True if the "Representative protein" entry contains
    the 'contaminant_tag', and otherwise False.

    Args:
        df: DataFrame to which the "Potential contaminant" column will be added.
        contaminant_tag: String used to identify potential contaminants.

    Returns:
        A copy of the input DataFrame, containing the "Potential contaminant" column.
    """
    # not tested #
    contaminants = [contaminant_tag in e for e in df["Representative protein"]]
    df = df.copy()
    df["Potential contaminant"] = contaminants
    return df


def _process_protein_entries(
    leading_protein_entries: list[list[str]],
    contaminant_tag: str,
    sort_proteins: bool,
    special_proteins: Optional[list] = None,
) -> pd.DataFrame:
    """Returns a DataFrame containing standardized protein entry columns.

    For each entry of 'leading_protein_entries', a list of of protein IDs is extracted.
    The first entry of the protein IDs is added to the "Protein reported by software"
    column. Multiple protein IDs are sorted if 'sort_proteins' is enabled. Multiple
    protein IDs are joined with ";" and added to the "Leading proteins" column. The
    first protein ID from the "Leading proteins" entry is added to the "Representative
    protein" column. If the "Representative protein" protein ID contains the
    'contaminant_tag' then True is added to the "Potential contaminant" column,
    otherwise False is added.

    Args:
        leading_protein_entries: A list containing lists of leading protein entries.
        contaminant_tag: String used to identify potential contaminants.
        sort_proteins: If True, protein entries in "Leading proteins" are sorted
            alphabetically ascending, with the exception that decoy proteins are always
            sorted to the back and special proteins are sorted to the front. If False,
            no sorting is applied.
        special_proteins: Optional, allows specifying a list of protein IDs that will
            always be used sorted to the beginning of the "Leading proteins" and thus be
            used as "Representative protein" when 'sort_proteins' is enabled.

    Returns:
        A DataFrame containing the columns "Protein reported by software",
        "Leading proteins", "Representative protein", and "Potential contaminant".
    """
    values_reported_id = []
    values_leading_ids = []
    values_representative_id = []
    values_contaminant = []
    for entries in leading_protein_entries:
        protein_ids = _extract_protein_ids(entries)
        id_reported_by_software = protein_ids[0]
        is_contaminant = _mark_contaminants(entries, contaminant_tag)
        if sort_proteins:
            protein_ids, is_contaminant = _sort_proteins_and_contaminants(
                protein_ids, is_contaminant, special_proteins
            )

        # Collect all entries
        values_reported_id.append(id_reported_by_software)
        values_leading_ids.append(";".join(protein_ids))
        values_representative_id.append(protein_ids[0])
        values_contaminant.append(is_contaminant[0])

    table = pd.DataFrame(
        {
            "Protein reported by software": values_reported_id,
            "Leading proteins": values_leading_ids,
            "Representative protein": values_representative_id,
            "Potential contaminant": values_contaminant,
        }
    )
    return table


def _extract_protein_ids(entries: list[str]) -> list[str]:
    """Returns a list of protein IDs, extracted from protein entries.

    If a protein entry contains two "|" it is considered a fasta header and the string
    between the first two "|" is extracted as the protein ID. Otherwise the entry is
    directly used as a protein ID.

    Args:
        entries: A list of protein entries.

    Returns:
        A list of protein IDs
    """
    # TODO: not tested #
    protein_ids = []
    for protein_entry in entries:
        if protein_entry.count("|") >= 2:
            protein_id = protein_entry.split("|")[1]
        else:
            protein_id = protein_entry
        protein_ids.append(protein_id)
    return protein_ids


def _mark_contaminants(entries: list[str], tag: str) -> list[bool]:
    """Returns a list of booleans, True for each entry that contains the tag.

    Args:
        entries: List of protein entries.
        tag: String used to identify potential contaminants.

    Returns:
        A list of booleans with the same length as 'entries'.
    """
    # TODO: not tested #
    return [True if tag in entry else False for entry in entries]
