""" Module for reading and homogenizing result tables from various MS analysis tools.

Currently MaxQuant and FragPipe protein tables are fully supported, and ion and peptide
tables are partly supported.

New column names:
- Representative protein
- Leading proteins
- Protein reported by software

Unified column names:
- Total peptides
- Spectral count "sample name"
- Unique spectral count "sample name"
- Total spectral count "sample name"
- Intensity "sample name"
- LFQ intensity "sample name"
- iBAQ intensity "sample name"

Todos:
- Add full support for ion (evidence) and peptide tables
  - FP reader:
    - For LFQ the most relevant files are combined_protein.tsv, combined_ion.tsv
    - For TMT the relevant files are protein.tsv, psm.tsv (might be in folders)
"""


from collections import OrderedDict
import os
from typing import Optional
import warnings

import numpy as np
import pandas as pd


try:
    import maspy._proteindb_refactoring as ProtDB
except ModuleNotFoundError:
    import maspy.proteindb as ProtDB

import msreport.helper as helper


class ResultReader:
    """Base Reader class, is by itself not functional."""

    filenames_default: dict[str, str]
    protected_columns: list[str]
    column_mapping: dict[str, str]
    column_tag_mapping: OrderedDict[str, str]
    sample_column_tags: list[str]

    def __init__(self):
        self.data_directory: str = ""
        self.filenames: dict[str, str] = {}

    def _read_file(self, which: str, sep: str = "\t") -> pd.DataFrame:
        """Read a result table from the data_directory

        Args:
            which: Lookup the filename in self.filenames. If 'which' is not present in
                self.filenames, 'which' is used as the filename.
            sep: Delimiter to use when reading the file
        """
        if which in self.filenames:
            filename = self.filenames[which]
        else:
            filename = which
        filepath = os.path.join(self.data_directory, filename)
        df = pd.read_csv(filepath, sep=sep)
        str_cols = df.select_dtypes(include=["object"]).columns
        df.loc[:, str_cols] = df.loc[:, str_cols].fillna("")
        return df

    def _rename_columns(self, df: pd.DataFrame, prefix_tag: bool) -> pd.DataFrame:
        """Returns a new DataFrame with renamed columns.

        First columns are renamed according to self.column_mapping. Next, tags in
        columns are renamed according to self.column_tag_mapping. Then, for columns
        containing sample names, sample names are and tags are rearranged. Columns from
        self.protected_column_positions are not modified.
        """
        new_df = df.copy()

        # Collect protected column positions
        protected_column_positions = {}
        for col in self.protected_columns:
            if col in new_df.columns:
                protected_column_positions[col] = new_df.columns.get_loc(col)

        # Rename columns
        new_df.rename(columns=self.column_mapping, inplace=True)
        for old_tag, new_tag in self.column_tag_mapping.items():
            new_df.columns = [c.replace(old_tag, new_tag) for c in new_df.columns]

        for tag in self.sample_column_tags:
            # Original columns have already been replaced with new names
            tag = self.column_tag_mapping.get(tag, tag).strip()
            new_df = _rearrange_column_tag(new_df, tag, prefix_tag)

        # Rename protected columns
        protected_column_mapping = {}
        for col, col_idx in protected_column_positions.items():
            protected_column_mapping[new_df.columns[col_idx]] = col
        new_df.rename(columns=protected_column_mapping, inplace=True)
        return new_df

    def _drop_columns(
        self, df: pd.DataFrame, columns_to_drop: list[str]
    ) -> pd.DataFrame:
        """Returns a new data frame without the specified columns."""
        remaining_columns = []
        for column in df.columns:
            if column not in columns_to_drop:
                remaining_columns.append(column)
        return df[remaining_columns].copy()

    def _drop_columns_by_tag(self, df: pd.DataFrame, tag: str) -> pd.DataFrame:
        """Returns a new data frame without columns containing 'tag'."""
        columns = helper.find_columns(df, tag, must_be_substring=False)
        return self._drop_columns(df, columns)

    def _add_data_directory(self, path) -> None:
        self.data_directory = path


class MQReader(ResultReader):
    """Import and preprocess MaxQuant result files.

    Attributes:
        filenames_default: (class attribute) Look up of filenames for the result files
            generated by MaxQuant.
        sample_column_tags: (class attribute) Column tags for which an additional column
            is present per sample.
        column_mapping: (class attribute) Used to rename original column names from
            MaxQuant with the internal standardized names.
        column_tag_mapping: (class attribute) Mapping of 'Old substring' to 'New
            substring' that will be replaced in column names. Used to rename intensity
            and spectral count columns.
        protein_info_columns: (class attribute) List of columns that contain protein
            specific information. Used to allow removing all protein specific
            information prior to changing the representative protein.
        protein_info_tags: (class attribute) List of tags present in columns that
            contain protein specific information per sample.
        data_directory (str): Location of the MaxQuant 'txt' folder
        contamination_tag (str): Substring present in protein IDs to identify them as
            potential contaminants.
    """

    filenames_default: dict[str, str] = {
        "proteins": "proteinGroups.txt",
        "peptides": "peptides.txt",
        "ions": "evidence.txt",
    }
    protected_columns: list[str] = ["iBAQ peptides"]
    sample_column_tags: list[str] = [
        "LFQ intensity",
        "Intensity",
        "iBAQ",
        "MS/MS count",
        "Sequence coverage",
    ]
    column_mapping: dict[str, str] = dict(
        [
            ("Peptides", "Total peptides"),
        ]
    )
    column_tag_mapping: OrderedDict[str, str] = OrderedDict(
        [("MS/MS count", "Spectral count"), ("iBAQ", "iBAQ intensity")]
    )
    protein_info_columns: list[str] = [
        "Protein names",
        "Gene names",
        "Fasta headers" "Sequence coverage [%]",
        "Unique + razor sequence coverage [%]",
        "Unique sequence coverage [%]",
        "Mol. weight [kDa]",
        "Sequence length",
        "Sequence lengths",
        "iBAQ peptides",
    ]
    protein_info_tags: list[str] = ["iBAQ", "Sequence coverage", "site positions"]

    def __init__(
        self, directory: str, isobar: bool = False, contaminant_tag: str = "CON__"
    ) -> None:
        """
        Args:
            directory: Location of the MaxQuant 'txt' folder
            isobar: True if quantification strategy was TMT, iTRAQ or similar
            contaminant_tag: Prefix of Protein ID entries to identify contaminations

        Attributes:
            data_directory: Location of the MaxQuant 'txt' folder
            filenames: Look up of filenames generated by MaxQuant
        """
        self._add_data_directory(directory)
        self.filenames: dict[str, str] = self.filenames_default
        self._isobar: bool = isobar
        self._contaminant_tag: str = contaminant_tag

    def import_proteins(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        drop_decoy: bool = True,
        drop_idbysite: bool = True,
        sort_proteins: bool = False,
        drop_protein_info: bool = False,
        special_proteins: list[str] = [],
    ) -> pd.DataFrame:
        """Read and process 'proteinGroups.txt' file.

        Args:
            filename: allows specifying an alternative filename, otherwise the default
                filename is used.
        """
        df = self._read_file("proteins" if filename is None else filename)
        df = self._add_protein_entries(df, sort_proteins, special_proteins)

        if drop_decoy:
            df = self._drop_decoy(df)
        if drop_idbysite:
            df = self._drop_idbysite(df)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
            for tag in self.protein_info_tags:
                df = self._drop_columns_by_tag(df, tag)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def import_peptides(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        drop_decoy: bool = True,
    ) -> pd.DataFrame:
        """Read and process 'peptides.txt' file.

        Args:
            filename: allows specifying an alternative filename, otherwise the default
                filename is used.
        """
        raise NotImplementedError("Needs to be reimplemented")
        df = self._read_file("peptides" if filename is None else filename)
        # df = self._add_protein_entries(df)
        if drop_decoy:
            df = self._drop_decoy(df)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    # def import_ions(self, drop_decoy: bool = True) -> pd.DataFrame:
    #     """ Read and process 'evidence.txt' file """
    #     df = self._read_file('ions')
    #     if drop_decoy:
    #         df = self._drop_decoy(df)
    #     return df

    def _add_protein_entries(
        self,
        df: pd.DataFrame,
        sort_proteins: bool = False,
        special_proteins: Optional[list] = None,
    ) -> pd.DataFrame:
        """Adds standardized protein entry columns to the data frame.

        Added columns are 'Leading proteins', 'Representative protein', and 'Protein
        reported by software'.

        'Leading proteins' contains all protein entries from the original 'Protein'
        plus 'Indistinguishable Proteins' columns. Multiple protein entries are
        separated by ';'. 'Protein reported by software' and 'Representative protein'
        contain the first entry from the new 'Leading proteins' column.

        TODO: Docstring needs expansion for sorting, contaminants and special proteins
        """
        # not tested directly, only via integration #
        leading_protein_entries = self._collect_leading_protein_entries(df)
        protein_entry_table = _process_protein_entries(
            leading_protein_entries,
            self._contaminant_tag,
            sort_proteins,
            special_proteins,
        )
        for key in protein_entry_table:
            df[key] = protein_entry_table[key]
        return df

    def _collect_leading_protein_entries(self, df: pd.DataFrame) -> list[str]:
        """TODO"""
        leading_protein_entries = []
        for majority_ids_entry, count_entry in zip(
            df["Majority protein IDs"], df["Peptide counts (all)"]
        ):
            proteins = majority_ids_entry.split(";")
            counts = [int(i) for i in count_entry.split(";")]
            highest_count = max(counts)
            protein_entries = [
                f for f, c in zip(proteins, counts) if c >= highest_count
            ]
            leading_protein_entries.append(protein_entries)
        return leading_protein_entries

    def _drop_decoy(self, df: pd.DataFrame) -> pd.DataFrame:
        """Removes rows with '+' in the 'Reverse' column"""
        return df.loc[df["Reverse"] != "+"]

    def _drop_idbysite(self, df: pd.DataFrame) -> pd.DataFrame:
        """Removes rows with '+' in the 'Only identified by site' column"""
        return df.loc[df["Only identified by site"] != "+"]


class FPReader(ResultReader):
    """Import and preprocess FragPipe result files.

    Attributes:
        filenames_default: (class attribute) Look up of filenames for the result files
            generated by FragPipe with LFQ quantification.
        filenames_isobar: (class attribute) Look up of filenames for the result files
            generated by FragPipe with isobaric quantification.
        sample_column_tags: (class attribute) Column tags for which an additional column
            is present per sample.
        column_mapping: (class attribute) Used to rename original column names from
            FragPipe with the internal standardized names.
        column_tag_mapping: (class attribute) Mapping of 'Old substring' to 'New
            substring' that will be replaced in column names. Used to rename intensity
            and spectral count columns.
        protein_info_columns: (class attribute) List of columns that contain protein
            specific information. Used to allow removing all protein specific
            information prior to changing the representative protein.
        protein_info_tags: (class attribute) List of tags present in columns that
            contain protein specific information per sample.
        data_directory (str): Location of the MaxQuant 'txt' folder
        contamination_tag (str): Substring present in protein IDs to identify them as
            potential contaminants.
    """

    filenames_default: dict[str, str] = {
        "proteins": "combined_protein.tsv",
        "peptides": "combined_peptide.tsv",
        "ions": "combined_ion.tsv",
    }
    filenames_isobar: dict[str, str] = {
        "proteins": "protein.tsv",
        "peptides": "peptide.tsv",
        "ions": "ion.tsv",
    }
    protected_columns: list[str] = []
    sample_column_tags: list[str] = [
        "Spectral Count",
        "Unique Spectral Count",
        "Total Spectral Count",
        "Intensity",
        "MaxLFQ Intensity",
    ]
    column_mapping: dict[str, str] = dict(
        [
            ("Combined Total Peptides", "Total peptides"),  # From LFQ
            ("Total Peptides", "Total peptides"),  # From TMT
        ]
    )
    column_tag_mapping: OrderedDict[str, str] = OrderedDict(
        [
            ("MaxLFQ Intensity", "LFQ intensity"),
            ("Total Spectral Count", "Total spectral count"),
            ("Unique Spectral Count", "Unique spectral count"),
            ("Spectral Count", "Spectral count"),
        ]
    )
    protein_info_columns: list[str] = [
        "Protein",
        "Protein ID",
        "Entry Name",
        "Gene",
        "Protein Length",
        "Organism",
        "Protein Existence",
        "Description",
        "Indistinguishable Proteins",
    ]
    protein_info_tags: list[str] = []

    def __init__(
        self, directory: str, isobar: bool = False, contaminant_tag: str = "contam_"
    ) -> None:
        """
        Args:
            directory: Location of the FragPipe result folder
            isobar: True if quantification strategy was TMT, iTRAQ or similar
            contaminant_tag: Prefix of Protein ID entries to identify contaminants

        Attributes:
            data_directory: Location of the FragPipe result folder
            filenames: Look up of filenames generated by FragPipe
        """
        self._add_data_directory(directory)
        self._isobar: bool = isobar
        self._contaminant_tag: str = contaminant_tag
        if not isobar:
            self.filenames = self.filenames_default
        else:
            self.filenames = self.filenames_isobar

    def import_proteins(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        sort_proteins: bool = True,
        drop_protein_info: bool = True,
        mark_contaminants: bool = True,
        special_proteins: list[str] = [],
    ) -> pd.DataFrame:
        """Read and process 'combined_protein.tsv' file.

        Note that is is essential to rename column names before attempting to rename
        sample columns, as the 'Intensity' substring is present in multiple columns.

        Args:
            filename: allows specifying an alternative filename, otherwise the default
                filename is used.
        """
        # TODO: not tested #
        df = self._read_file("proteins" if filename is None else filename)
        df = self._add_protein_entries(df, sort_proteins, special_proteins)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
            for tag in self.protein_info_tags:
                df = self._drop_columns_by_tag(df, tag)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def import_ions(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
    ) -> pd.DataFrame:
        """Read and process 'combined_ion.tsv' file.

        Adds the columns 'Representative protein' and 'Protein reported by software'.

        Args:
            filename: allows specifying an alternative filename, otherwise the default
                filename is used.
        """
        # TODO: not tested #
        df = self._read_file("ions" if filename is None else filename)

        # FUTURE: replace this by _add_protein_entries(df, False) if FragPipe adds
        #         'Indistinguishable Proteins' to the ion table.
        df["Representative protein"] = df["Protein ID"]
        df["Protein reported by software"] = df["Protein ID"]

        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def _add_protein_entries(
        self,
        df: pd.DataFrame,
        sort_proteins: bool,
        special_proteins: Optional[list] = None,
    ) -> pd.DataFrame:
        """Adds standardized protein entry columns to the data frame.

        Added columns are 'Leading proteins', 'Representative protein', and 'Protein
        reported by software'.

        'Leading proteins' contains all protein entries from the original 'Protein'
        plus 'Indistinguishable Proteins' columns. Multiple protein entries are
        separated by ';'. 'Protein reported by software' and 'Representative protein'
        contain the first entry from the new 'Leading proteins' column.

        TODO: Docstring needs expansion for sorting, contaminants and special proteins
        """
        leading_protein_entries = self._collect_leading_protein_entries(df)
        protein_entry_table = _process_protein_entries(
            leading_protein_entries,
            self._contaminant_tag,
            sort_proteins,
            special_proteins,
        )
        for key in protein_entry_table:
            df[key] = protein_entry_table[key]
        return df

    def _collect_leading_protein_entries(self, df: pd.DataFrame) -> list[str]:
        leading_protein_entries = []
        for protein_entry, indist_protein_entry in zip(
            df["Protein"], df["Indistinguishable Proteins"]
        ):
            protein_entries = [protein_entry]
            if indist_protein_entry:
                for entry in indist_protein_entry.split(", "):
                    protein_entries.append(entry)
            leading_protein_entries.append(protein_entries)
        return leading_protein_entries


class SpectronautReader(ResultReader):
    """Import and preprocess Spectronaut DIA result files.

    For now, look for a file that ends with report.X (X=xls, tsv, csv)
    """

    protected_columns: list[str] = []
    column_mapping: dict[str, str] = dict(
        [
            ("PG.Cscore", "Protein cscore"),
            ("PG.NrOfStrippedSequencesIdentified (Experiment-wide)", "Total peptides"),
            ("PG.NrOfPrecursorsIdentified (Experiment-wide)", "Total ions"),
            ("PG.Cscore", "Cscore"),
        ]
    )
    sample_column_tags: list[str] = [
        ".PG.NrOfPrecursorsIdentified",
        ".PG.IBAQ",
        ".PG.Quantity",
        ".PG.NrOfPrecursorsUsedForQuantification",
        ".PG.NrOfStrippedSequencesUsedForQuantification",
    ]
    column_tag_mapping: OrderedDict[str, str] = OrderedDict(
        [
            (".PG.NrOfPrecursorsIdentified", " Ion count"),
            (".PG.IBAQ", " iBAQ intensity"),
            (".PG.Quantity", " Intensity"),
            (".PG.NrOfPrecursorsUsedForQuantification", " Quantified ion count"),
            (
                ".PG.NrOfStrippedSequencesUsedForQuantification",
                " Total quantified peptides",
            ),
        ]
    )
    protein_info_columns: list[str] = [
        "PG.ProteinGroups",
        "PG.ProteinAccessions",
        "PG.Genes",
        "PG.Organisms",
        "PG.ProteinDescriptions",
        "PG.UniProtIds",
        "PG.ProteinNames",
        "PG.FastaHeaders",
        "PG.OrganismId",
        "PG.MolecularWeight",
    ]
    protein_info_tags: list[str] = []

    def __init__(self, directory: str, contaminant_tag: str = "contam_") -> None:
        self._add_data_directory(directory)
        self._contaminant_tag: str = contaminant_tag
        self.filenames: dict[str, str] = {}
        self.design: Optional[pd.DataFrame] = None
        self._import_spectronaut_design()

    def import_proteins(
        self,
        filename: Optional[str] = None,
        rename_columns: bool = True,
        prefix_column_tags: bool = True,
        sort_proteins: bool = True,
        drop_protein_info: bool = True,
        mark_contaminants: bool = True,
        special_proteins: list[str] = [],
    ) -> pd.DataFrame:
        """Read and process a Spectronaut protein report file."""
        # Find report filename
        if filename is None:
            report_endings = ["report.xls", "report.tsv", "report.csv"]
            matched_filenames = []
            for filename in os.listdir(self.data_directory):
                if any([filename.lower().endswith(s) for s in report_endings]):
                    matched_filenames.append(filename)
            filename = matched_filenames[0]

        df = self._read_file(filename)
        df = self._tidy_up_sample_columns(df)
        df = self._add_protein_entries(df, sort_proteins, special_proteins)
        if drop_protein_info:
            df = self._drop_columns(df, self.protein_info_columns)
            for tag in self.protein_info_tags:
                df = self._drop_columns_by_tag(df, tag)
        if rename_columns:
            df = self._rename_columns(df, prefix_column_tags)
        return df

    def _import_spectronaut_design(self):
        report_endings = [f"conditionsetup{s}" for s in (".xls", ".tsv", ".csv")]
        matched_filenames = []
        for filename in os.listdir(self.data_directory):
            if any([filename.lower().endswith(s) for s in report_endings]):
                matched_filenames.append(filename)
        if matched_filenames:
            filename = matched_filenames[0]
            condition_setup = self._read_file(filename)

            condition_setup["Sample"] = (
                condition_setup["Condition"]
                + "_"
                + condition_setup["Replicate"].astype(str)
            )
            self.design = pd.DataFrame(
                {
                    "Sample": condition_setup["Sample"],
                    "Experiment": condition_setup["Condition"],
                    "File name": condition_setup["File Name"],
                    "Run label": condition_setup["Run Label"],
                }
            )
        else:
            self.design = None

    def _add_protein_entries(
        self,
        df: pd.DataFrame,
        sort_proteins: bool = False,
        special_proteins: Optional[list] = None,
    ) -> pd.DataFrame:
        """Adds standardized protein entry columns to the data frame.

        Added columns are 'Leading proteins', 'Representative protein', and 'Protein
        reported by software'.

        'Leading proteins' contains all protein entries from the original 'Protein'
        plus 'Indistinguishable Proteins' columns. Multiple protein entries are
        separated by ';'. 'Protein reported by software' and 'Representative protein'
        contain the first entry from the new 'Leading proteins' column.

        TODO: Docstring needs expansion for sorting, contaminants and special proteins
        """
        # not tested directly, only via integration #
        leading_protein_entries = self._collect_leading_protein_entries(df)
        protein_entry_table = _process_protein_entries(
            leading_protein_entries,
            self._contaminant_tag,
            sort_proteins,
            special_proteins,
        )
        for key in protein_entry_table:
            df[key] = protein_entry_table[key]
        return df

    def _collect_leading_protein_entries(self, df: pd.DataFrame) -> list[str]:
        """TODO"""
        leading_protein_entries = [
            entries.split(";") for entries in df["PG.ProteinAccessions"]
        ]
        return leading_protein_entries

    def _tidy_up_sample_columns(self, df):
        df = df.copy()
        columns = df.columns
        with warnings.catch_warnings():
            warnings.simplefilter(action="ignore", category=FutureWarning)

            # Remove leading brackets
            columns = columns.str.replace(r"^\[[0-9]+\] ", "")
            # Replace Spectronaut run labels with sample names
            if self.design is not None:
                for sample, label in zip(
                    self.design["Sample"], self.design["Run label"]
                ):
                    columns = columns.str.replace(label, sample)
            df.columns = columns
        return df


def add_protein_annotations(
    table: pd.DataFrame, fasta_path: str, id_column: str = "Representative protein"
) -> None:
    """Adds descriptive columns for the representative protein.

    The added columns always includes "Fasta header", "Protein length", "iBAQ peptides",
    and if possible "Protein entry name" and "Gene name".
    """
    # not tested #
    protein_db = ProtDB.importProteinDatabase(fasta_path, contaminationTag="contam_")

    new_columns = {
        "Protein entry name": [],
        "Gene name": [],
        "Fasta header": [],
        "Protein length": [],
        "iBAQ peptides": [],
    }
    for protein_id in table[id_column]:
        if protein_id in protein_db.proteins:
            sequence = protein_db[protein_id].sequence
            header_info = protein_db[protein_id].headerInfo

            entry_name = header_info["entry"] if "entry" in header_info else ""
            gene_name = header_info["GN"] if "GN" in header_info else ""
            fasta_header = protein_db[protein_id].fastaHeader
            length = protein_db[protein_id].length()
            ibaq_peptides = helper.calculate_tryptic_ibaq_peptides(sequence)
        else:
            entry_name = ""
            gene_name = ""
            fasta_header = ""
            length = np.nan
            ibaq_peptides = np.nan

        new_columns["Protein entry name"].append(entry_name)
        new_columns["Gene name"].append(gene_name)
        new_columns["Fasta header"].append(fasta_header)
        new_columns["Protein length"].append(length)
        new_columns["iBAQ peptides"].append(ibaq_peptides)

    for column in new_columns:
        table[column] = new_columns[column]


def add_sequence_coverage(
    protein_table: pd.DataFrame,
    peptide_table: pd.DataFrame,
    id_column: str = "Protein reported by software",
) -> None:
    """Calculates 'Sequence coverage' and adds it to the protein table.

    Requires the columns 'Start' and 'End' in the peptide_table, and 'Protein length' in
    the protein_table.
    """
    # not tested #
    peptide_positions = {}
    for protein_id, peptide_group in peptide_table.groupby(by=id_column):
        positions = [
            (s, e) for s, e in zip(peptide_group["Start"], peptide_group["End"])
        ]
        peptide_positions[protein_id] = sorted(positions)

    sequence_coverages = []
    for protein_id, protein_length in zip(
        protein_table[id_column], protein_table["Protein length"]
    ):
        sequence_coverage = helper.calculate_sequence_coverage(
            protein_length, peptide_positions[protein_id], ndigits=1
        )
        sequence_coverages.append(sequence_coverage)
    protein_table["Sequence coverage"] = sequence_coverages


def add_ibaq_intensities(
    table: pd.DataFrame,
    normalize: bool = True,
    ibaq_peptide_column: str = "iBAQ peptides",
    intensity_tag: str = "Intensity",
    ibaq_tag: str = "iBAQ intensity",
) -> None:
    """Calculates iBAQ intensities.

    Requires a column containing the theoretical number of iBAQ peptides.

    Args:
        normalize: Scales iBAQ intensities per sample so that the sum of all iBAQ
            intensities is equal to the sum of all Intensities.
    """
    for intensity_column in helper.find_columns(table, intensity_tag):
        ibaq_column = intensity_column.replace(intensity_tag, ibaq_tag)
        table[ibaq_column] = table[intensity_column] / table[ibaq_peptide_column]

        if normalize:
            factor = table[intensity_column].sum() / table[ibaq_column].sum()
            table[ibaq_column] = table[ibaq_column] * factor


def add_peptide_positions(
    table: pd.DataFrame,
    fasta_path: str,
    protein_column: str = "Representative protein",
    peptide_column: str = "Peptide Sequence",
) -> None:
    """Adds protein 'Start' and 'End' positions fo peptides to the table."""
    # TODO: replace fasta_path by a dictionary of protein sequences
    # not tested #
    protein_db = ProtDB.importProteinDatabase(fasta_path, contaminationTag="contam_")

    peptide_positions = {"Start": [], "End": []}
    for peptide, protein_id in zip(table[peptide_column], table[protein_column]):
        sequence = protein_db[protein_id].sequence
        start = sequence.find(peptide) + 1
        end = start + len(peptide) - 1
        if start == 0:
            start, end = -1, -1
        peptide_positions["Start"].append(start)
        peptide_positions["End"].append(end)

    for key in peptide_positions:
        table[key] = peptide_positions[key]


def propagate_representative_protein(
    target_table: pd.DataFrame, source_table: pd.DataFrame
) -> None:
    """Propagates the 'Representative protein' from the source to the target
    table.

    The column 'Protein reported by software' is used to match entries between the two
    tables, and entries from 'Representative protein' are propageted from the
    source_table to the target_table.
    """
    # not tested #
    protein_lookup = {}
    for old, new in zip(
        source_table["Protein reported by software"],
        source_table["Representative protein"],
    ):
        protein_lookup[old] = new

    new_protein_ids = []
    for old in target_table["Protein reported by software"]:
        new_protein_ids.append(protein_lookup[old])
    target_table["Representative protein"] = new_protein_ids


def extract_sample_names(df: pd.DataFrame, tag: str) -> list[str]:
    """Extract sample names from columns containing the 'tag'"""
    columns = helper.find_columns(df, tag)
    sample_names = _find_remaining_substrings(columns, tag)
    return sample_names


def _rearrange_column_tag(df: pd.DataFrame, tag: str, prefix: bool) -> pd.DataFrame:
    """Moves the column tag to the beginning or end of each column.

    Args:
        df: Rearrange columns in this DataFrame
        tag: A substring that when found in column names should be moved to the
            beginning or end of the column name
        prefix: if true, the tag string is moved to the beginning of the new column
            names, else to the end.
    """
    old_columns = helper.find_columns(df, tag)
    new_columns = []
    for column_name in old_columns:
        column_name = column_name.replace(tag, "").strip()
        if prefix:
            new_column_name = " ".join([tag, column_name]).strip()
        else:
            new_column_name = " ".join([column_name, tag]).strip()
        new_columns.append(new_column_name)
    column_lookup = dict(zip(old_columns, new_columns))
    df = df.rename(columns=column_lookup, inplace=False)
    return df


def _find_remaining_substrings(strings: list[str], split_with: str) -> list[str]:
    """Find the remaining part from several strings after splitting."""
    substrings = []
    for string in strings:
        substrings.extend([s.strip() for s in string.split(split_with)])
    # Remove empty entries
    substrings = sorted(set(filter(None, substrings)))
    return substrings


def _sort_leading_proteins(
    df: pd.DataFrame,
    contaminant_tag: Optional[str] = None,
    special_proteins: list[str] = [],
) -> pd.DataFrame:
    """Sorts protein entries from the 'Leading proteins' column.

    Multiple entries in the 'Leading proteins' column must be separated by ';'. After
    sorting, special proteins are listed first and proteins containing the
    contamination tag are listed last. The other proteins are sorted alphabetically
    ascending.

    The first entry from the sorted 'Leading proteins' is written into the
    'Representative protein' column.

    Returns:
        A new dataframe containing sorting leading protein entries and updated the
            representative proteins.
    """
    sorting_tag_levels = {}
    if contaminant_tag is not None:
        sorting_tag_levels[contaminant_tag] = 1
    sorting_tag_levels.update({p: -1 for p in special_proteins})

    leading_entries = []
    representative_entries = []
    for leading_proteins in df["Leading proteins"]:
        proteins = leading_proteins.split(";")
        fastas, sorted_proteins, names = _sort_fasta_entries(
            proteins, sorting_tag_levels
        )
        representative_entries.append(sorted_proteins[0])
        leading_entries.append(";".join(sorted_proteins))

    df = df.copy()
    df["Representative protein"] = representative_entries
    df["Leading proteins"] = leading_entries
    return df


def _sort_proteins_and_contaminants(
    proteins: list[str],
    contaminants: Optional[list[bool]] = None,
    special_proteins: Optional[list[str]] = None,
) -> list[str]:
    """Sorts protein and contaminant entries.

    Proteins that are in the list of special proteins are listed first, then normal
    proteins and finally contaminants. Then each group is sorted alphabetically.

    Args:
        proteins: List of protein names to be sorted.
        contaminants: List of booleans, indicating whether a protein is a contaminant.
        sorting_tag_levels: Mapping of tags to sort levels. If the tag string is present
            in a protein name, the sort level of this tag is used.

    Returns:
        Sorted lists of proteins.
    """
    if contaminants is not None:
        sorting = [int(pc) for pc in contaminants]
    else:
        contaminants = [None for p in proteins]
        sorting = [0 for p in proteins]

    if special_proteins is not None:
        _sorting = []
        for p, sort_level in zip(proteins, sorting):
            _sorting.append(sort_level + (-2 if p in special_proteins else 0))
        sorting = _sorting

    sorted_values = sorted(zip(sorting, proteins, contaminants))
    _, proteins, contaminants = [list(v) for v in zip(*(sorted_values))]
    return proteins, contaminants


def _sort_fasta_entries(
    fasta_entries: list[str], sorting_tag_levels: dict[str, int] = {}
) -> list[list[str], list[str], list[str]]:
    """Return sorted fasta headers, protein ids, entry names.

    Fasta headers are first sorted according to the sort level of each header in
    ascending order, and those with the same entries are sorted alphabetically
    according to the UniqueID of the fasta header. By default each fasta entry has a
    sort level of 0.

    Args:
        sorting_tag_levels: Mapping of tags to sort levels. If the tag string is present
            in the UniqueID entry of the fasta headers, the sort level of this tag is
            used.

    Returns:
        sorted lists of [fasta headers, protein ids, entry names]
    """
    values = []
    for fasta in fasta_entries:
        if fasta.count("|") >= 2:
            protein = fasta.split("|")[1]
            name = fasta.split("|")[2].split(" ")[0]
        else:
            protein = fasta
            name = fasta
        sort_level = 0
        for tag, level in sorting_tag_levels.items():
            if tag in protein:
                sort_level = level
        values.append((sort_level, protein, fasta, name))
    values.sort()
    sort_levels, proteins, fastas, names = [list(v) for v in zip(*(values))]
    return fastas, proteins, names


def _mark_potential_contaminants(
    df: pd.DataFrame, contaminant_tag: str
) -> pd.DataFrame:
    """Adds a 'Potential contaminant' column to the data frame.

    'Potential contaminant' is True if the 'Representative protein' entry contains the
    'contaminant_tag', and otherwise False.
    """
    # not tested #
    contaminants = [contaminant_tag in e for e in df["Representative protein"]]
    df = df.copy()
    df["Potential contaminant"] = contaminants
    return df


def _extract_protein_ids(entries: list[str]) -> list[str]:
    # TODO: not tested #
    protein_ids = []
    for protein_entry in entries:
        if protein_entry.count("|") >= 2:
            protein_id = protein_entry.split("|")[1]
        else:
            protein_id = protein_entry
        protein_ids.append(protein_id)
    return protein_ids


def _mark_contaminants(entries: list[str], tag: str) -> list[bool]:
    """Returns a list of booleans, true for each entry that contains the tag."""
    # TODO: not tested #
    return [True if tag in entry else False for entry in entries]


def _process_protein_entries(
    leading_protein_entries: list[str],
    contaminant_tag: str,
    sort_proteins: bool,
    special_proteins: Optional[list] = None,
) -> pd.DataFrame:
    values_reported_id = []
    values_leading_ids = []
    values_representative_id = []
    values_contaminant = []
    for entries in leading_protein_entries:
        protein_ids = _extract_protein_ids(entries)
        id_reported_by_software = protein_ids[0]
        is_contaminant = _mark_contaminants(entries, contaminant_tag)
        if sort_proteins:
            protein_ids, is_contaminant = _sort_proteins_and_contaminants(
                protein_ids, is_contaminant, special_proteins
            )

        # Collect all entries
        values_reported_id.append(id_reported_by_software)
        values_leading_ids.append(";".join(protein_ids))
        values_representative_id.append(protein_ids[0])
        values_contaminant.append(is_contaminant[0])

    table = pd.DataFrame(
        {
            "Protein reported by software": values_reported_id,
            "Leading proteins": values_leading_ids,
            "Representative protein": values_representative_id,
            "Potential contaminant": values_contaminant,
        }
    )
    return table
